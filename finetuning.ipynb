{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook contains a notebook version of the finetune process. We'll do exactly the same but using GCP instances.","metadata":{"id":"VhAJBkZKiyyH"}},{"cell_type":"code","source":"!pip install datasets unsloth xformers","metadata":{"id":"AEitO1fXjBiy","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:33:59.584380Z","iopub.execute_input":"2025-05-11T03:33:59.584969Z","iopub.status.idle":"2025-05-11T03:37:09.705037Z","shell.execute_reply.started":"2025-05-11T03:33:59.584942Z","shell.execute_reply":"2025-05-11T03:37:09.704062Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting unsloth\n  Downloading unsloth-2025.4.7-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xformers\n  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nCollecting unsloth_zoo>=2025.4.4 (from unsloth)\n  Downloading unsloth_zoo-2025.4.4-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.5.1+cu124)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.1.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.51.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.3.0)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.32.2)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.20.1+cu124)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (4.13.1)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.1.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.4.4->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.4->unsloth) (11.1.0)\nCollecting msgspec (from unsloth_zoo>=2025.4.4->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.6.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.1)\nCollecting hf-xet>=0.1.4 (from huggingface_hub[hf_xet]>=0.30.0->unsloth_zoo>=2025.4.4->unsloth)\n  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\nDownloading unsloth-2025.4.7-py3-none-any.whl (218 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.5/218.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.4.4-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading tyro-0.9.19-py3-none-any.whl (124 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, hf-xet, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu124\n    Uninstalling torch-2.5.1+cu124:\n      Successfully uninstalled torch-2.5.1+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu124\n    Uninstalling torchvision-0.20.1+cu124:\n      Successfully uninstalled torchvision-0.20.1+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.7.0 which is incompatible.\ntorchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.7.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 fsspec-2024.12.0 hf-xet-1.1.0 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 shtab-1.7.2 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0 trl-0.15.2 tyro-0.9.19 unsloth-2025.4.7 unsloth_zoo-2025.4.4 xformers-0.0.30\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"6Iyxg8t8ABRz","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:37:09.706644Z","iopub.execute_input":"2025-05-11T03:37:09.706965Z","iopub.status.idle":"2025-05-11T03:37:10.154300Z","shell.execute_reply.started":"2025-05-11T03:37:09.706936Z","shell.execute_reply":"2025-05-11T03:37:10.153544Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fdd8116aea941298b509bb4eca6c942"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"First of all, we are going to load the dataset containing Rick & Morty transcripts.","metadata":{"id":"CY0pv4a3FvbG"}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom unsloth import standardize_sharegpt\n\ndataset = load_dataset(\"theneuralmaze/rick-and-morty-transcripts-sharegpt\", split=\"train\")\n\ndataset = standardize_sharegpt(dataset)\ndataset = dataset.train_test_split(test_size=0.1, seed=42)\ntrain_dataset = dataset[\"train\"]\nval_dataset = dataset[\"test\"]","metadata":{"id":"g1IPNHYvGHBA","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:52:30.323359Z","iopub.execute_input":"2025-05-11T03:52:30.323641Z","iopub.status.idle":"2025-05-11T03:52:31.569979Z","shell.execute_reply.started":"2025-05-11T03:52:30.323622Z","shell.execute_reply":"2025-05-11T03:52:31.569167Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(\"Number of rows: \", len(train_dataset))\nprint(\"Number of rows val: \", len(val_dataset))","metadata":{"id":"J2E8Gj75mfnw","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:53:17.411285Z","iopub.execute_input":"2025-05-11T03:53:17.411978Z","iopub.status.idle":"2025-05-11T03:53:17.416050Z","shell.execute_reply.started":"2025-05-11T03:53:17.411953Z","shell.execute_reply":"2025-05-11T03:53:17.415192Z"}},"outputs":[{"name":"stdout","text":"Number of rows:  1356\nNumber of rows val:  151\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train_dataset[0]","metadata":{"id":"WPhJgxYomaY3","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:53:36.168702Z","iopub.execute_input":"2025-05-11T03:53:36.169157Z","iopub.status.idle":"2025-05-11T03:53:36.176288Z","shell.execute_reply.started":"2025-05-11T03:53:36.169136Z","shell.execute_reply":"2025-05-11T03:53:36.175578Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'content': \"You are an interdimensional genius scientist named Rick Sanchez.\\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).\",\n   'role': 'system'},\n  {'content': \"Why don't you guys just fuck and get it over with.\",\n   'role': 'user'},\n  {'content': \"Okay, well thank you, Summer, but I think I've got a better option.\",\n   'role': 'assistant'}]}"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"Now, let's load both the model (Llama 3.1 8B) and the tokenizer.","metadata":{"id":"Ei0rXX5tGcvb"}},{"cell_type":"code","source":"import torch\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments, TextStreamer\nfrom unsloth.chat_templates import get_chat_template\nfrom unsloth import FastLanguageModel, is_bfloat16_supported\n\nmax_seq_length = 2048\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    load_in_4bit = True,\n    dtype = torch.float16,\n    device_map = {\"\": torch.cuda.current_device()}\n)","metadata":{"id":"36CypqJwjo5b","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:58:19.785492Z","iopub.execute_input":"2025-05-11T03:58:19.785814Z","iopub.status.idle":"2025-05-11T03:58:19.815093Z","shell.execute_reply.started":"2025-05-11T03:58:19.785792Z","shell.execute_reply":"2025-05-11T03:58:19.814067Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2705188770.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_templates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_chat_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_bfloat16_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'TrainingArguments' from 'trl' (/usr/local/lib/python3.11/dist-packages/trl/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'TrainingArguments' from 'trl' (/usr/local/lib/python3.11/dist-packages/trl/__init__.py)","output_type":"error"}],"execution_count":21},{"cell_type":"markdown","source":"Instead of a full finetuning, we are going to use LoRa finetuning.","metadata":{"id":"MTPQpy0oGzv1"}},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=32,\n    lora_alpha=64,\n    lora_dropout=0,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n    use_rslora=True,\n    use_gradient_checkpointing=\"unsloth\"\n)","metadata":{"id":"-oVSVa7nl1bf","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:55:26.347121Z","iopub.execute_input":"2025-05-11T03:55:26.347416Z","iopub.status.idle":"2025-05-11T03:55:33.441562Z","shell.execute_reply.started":"2025-05-11T03:55:26.347396Z","shell.execute_reply":"2025-05-11T03:55:33.440681Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.4.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"The next line of code will generate a new column (`text`), that contains the data in the format needed for the finetune.","metadata":{"id":"1twwKyscHx2S"}},{"cell_type":"code","source":"from unsloth import apply_chat_template\n\nchat_template = \"\"\"<|im_start|>system\n{SYSTEM}<|im_end|>\n<|im_start|>user\n{INPUT}<|im_end|>\n<|im_start|>assistant\n{OUTPUT}<|im_end|>\"\"\"\n\ntrain_dataset = apply_chat_template(train_dataset, tokenizer=tokenizer, chat_template=chat_template)\nval_dataset = apply_chat_template(val_dataset, tokenizer=tokenizer, chat_template=chat_template)\n","metadata":{"id":"meJjl4Qins12","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:55:51.789140Z","iopub.execute_input":"2025-05-11T03:55:51.789426Z","iopub.status.idle":"2025-05-11T03:55:52.518480Z","shell.execute_reply.started":"2025-05-11T03:55:51.789405Z","shell.execute_reply":"2025-05-11T03:55:52.517707Z"}},"outputs":[{"name":"stderr","text":"Unsloth: We automatically added an EOS token to stop endless generations.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd1c9963402145ada796c872d5252802"}},"metadata":{}},{"name":"stderr","text":"Unsloth: We automatically added an EOS token to stop endless generations.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/151 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e767b4eb57f54d839a6d6370bb23bd4e"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"train_dataset[0]\nval_dataset[0]","metadata":{"id":"ITyqUuAUqVmG","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:56:05.132074Z","iopub.execute_input":"2025-05-11T03:56:05.132349Z","iopub.status.idle":"2025-05-11T03:56:05.138186Z","shell.execute_reply.started":"2025-05-11T03:56:05.132329Z","shell.execute_reply":"2025-05-11T03:56:05.137546Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'content': \"You are an interdimensional genius scientist named Rick Sanchez.\\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).\",\n   'role': 'system'},\n  {'content': 'Mr. Sanchez gets anything he wants!', 'role': 'user'},\n  {'content': 'The resort’s covered in an immortality field. You can’t die here. That’s the gimmick.',\n   'role': 'assistant'}],\n 'text': \"<|begin_of_text|><|im_start|>system\\nYou are an interdimensional genius scientist named Rick Sanchez.\\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).<|im_end|>\\n<|im_start|>user\\nMr. Sanchez gets anything he wants!<|im_end|>\\n<|im_start|>assistant\\nThe resort’s covered in an immortality field. You can’t die here. That’s the gimmick.<|im_end|><|end_of_text|>\"}"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"Finally, let's train for 5 epochs.","metadata":{"id":"aosfrXgKIYmw"}},{"cell_type":"code","source":"!pip install -U transformers trl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T04:02:54.208245Z","iopub.execute_input":"2025-05-11T04:02:54.208856Z","iopub.status.idle":"2025-05-11T04:03:05.973847Z","shell.execute_reply.started":"2025-05-11T04:02:54.208833Z","shell.execute_reply":"2025-05-11T04:03:05.973060Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting transformers\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.15.2)\nCollecting trl\n  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.3.0)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.5.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (14.0.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.7.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.11.16)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.19.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.11.1.6)\nRequirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.3.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=2.0.0->accelerate>=0.34.0->trl) (75.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\nDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.17.0-py3-none-any.whl (348 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: transformers, trl\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n  Attempting uninstall: trl\n    Found existing installation: trl 0.15.2\n    Uninstalling trl-0.15.2:\n      Successfully uninstalled trl-0.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nunsloth 2025.4.7 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9, but you have trl 0.17.0 which is incompatible.\nunsloth-zoo 2025.4.4 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9, but you have trl 0.17.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed transformers-4.51.3 trl-0.17.0\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    packing=True,\n    args=TrainingArguments(\n        learning_rate=5e-5,\n        lr_scheduler_type=\"linear\",\n        per_device_train_batch_size=32,\n        gradient_accumulation_steps=4,\n        num_train_epochs=1,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=1,\n        eval_strategy=\"steps\",\n        eval_steps=10,  # Adjust depending on dataset size\n        save_strategy='steps',\n        save_steps=10,\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_loss\",\n        greater_is_better=False,\n        output_dir=\"output\",\n        seed=0,\n        report_to=\"none\",\n    ),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n)\n\ntrainer.train()\n","metadata":{"id":"-9mMwBJepJq4","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T04:58:58.978747Z","iopub.execute_input":"2025-05-11T04:58:58.979286Z","iopub.status.idle":"2025-05-11T05:10:40.727511Z","shell.execute_reply.started":"2025-05-11T04:58:58.979264Z","shell.execute_reply":"2025-05-11T05:10:40.726928Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\nUnsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,356 | Num Epochs = 1 | Total steps = 10\nO^O/ \\_/ \\    Batch size per device = 32 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (32 x 4 x 1) = 128\n \"-____-\"     Trainable parameters = 48,627,712/3,000,000,000 (1.62% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 10:40, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.675800</td>\n      <td>0.879133</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=10, training_loss=0.6990058958530426, metrics={'train_runtime': 699.023, 'train_samples_per_second': 1.94, 'train_steps_per_second': 0.014, 'total_flos': 4445578361241600.0, 'train_loss': 0.6990058958530426})"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"Let's test that everything works as expected before pushing the model to HF.","metadata":{"id":"kaCp13JIY36U"}},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\nSYSTEM_PROMPT = \"\"\"You are an interdimensional genius scientist named Rick Sanchez.\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).\"\"\"\n\n\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\"role\": \"user\", \"content\": \"Are you a bad person?\"},\n]\n\ninput_ids = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt = True,\n    return_tensors = \"pt\",\n).to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt = True)\n_ = model.generate(input_ids, \n                   streamer = text_streamer, \n                   max_new_tokens = 128, \n                   pad_token_id = tokenizer.eos_token_id,\n                   temperature=0.8,\n                   repetition_penalty=1.2,\n)","metadata":{"id":"Nx4-sw9N5S6u","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T05:12:26.277480Z","iopub.execute_input":"2025-05-11T05:12:26.278052Z","iopub.status.idle":"2025-05-11T05:12:27.240312Z","shell.execute_reply.started":"2025-05-11T05:12:26.278029Z","shell.execute_reply":"2025-05-11T05:12:27.239788Z"}},"outputs":[{"name":"stdout","text":"Bad? Bad people don’t get a pass.<|im_end|><|end_of_text|>\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"Push the GGUF model to HF for later download.","metadata":{"id":"Gdq_KGTjY9xm"}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T05:13:26.240097Z","iopub.execute_input":"2025-05-11T05:13:26.240915Z","iopub.status.idle":"2025-05-11T05:13:26.344784Z","shell.execute_reply.started":"2025-05-11T05:13:26.240890Z","shell.execute_reply":"2025-05-11T05:13:26.344028Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"from huggingface_hub import create_repo, login\ncreate_repo(\"RickLLama-3.2-3B\", repo_type=\"model\", private=True)  # Set private=True if needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T05:14:41.447940Z","iopub.execute_input":"2025-05-11T05:14:41.448191Z","iopub.status.idle":"2025-05-11T05:14:41.942175Z","shell.execute_reply.started":"2025-05-11T05:14:41.448174Z","shell.execute_reply":"2025-05-11T05:14:41.941527Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/falcon281/RickLLama-3.2-3B', endpoint='https://huggingface.co', repo_type='model', repo_id='falcon281/RickLLama-3.2-3B')"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"model.push_to_hub_gguf(\"falcon281/RickLLama-3.2-3B\", tokenizer)","metadata":{"id":"kU1rj6VTztbL","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T05:14:44.682767Z","iopub.execute_input":"2025-05-11T05:14:44.683054Z","iopub.status.idle":"2025-05-11T05:20:23.284971Z","shell.execute_reply.started":"2025-05-11T05:14:44.683035Z","shell.execute_reply":"2025-05-11T05:20:23.283965Z"}},"outputs":[{"name":"stderr","text":"Unsloth: ##### The current model auto adds a BOS token.\nUnsloth: ##### Your chat template has a BOS token. We shall remove it temporarily.\n","output_type":"stream"},{"name":"stdout","text":"Cloning into 'llama.cpp'...\nSubmodule 'kompute' (https://github.com/nomic-ai/kompute.git) registered for path 'ggml/src/ggml-kompute/kompute'\nCloning into '/kaggle/working/llama.cpp/ggml/src/ggml-kompute/kompute'...\nSubmodule path 'ggml/src/ggml-kompute/kompute': checked out '4565194ed7c32d1d2efa32ceab4d3c6cae006306'\nRequirement already satisfied: gguf in /usr/local/lib/python3.11/dist-packages (0.16.3)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (3.20.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from gguf) (1.26.4)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from gguf) (6.0.2)\nRequirement already satisfied: sentencepiece<=0.2.0,>=0.1.98 in /usr/local/lib/python3.11/dist-packages (from gguf) (0.2.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from gguf) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->gguf) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->gguf) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->gguf) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->gguf) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->gguf) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->gguf) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->gguf) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->gguf) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->gguf) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->gguf) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->gguf) (2024.2.0)\nmake: Entering directory '/kaggle/working/llama.cpp'\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found Git: /usr/bin/git (found version \"2.34.1\")\n-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n-- Found Threads: TRUE\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\n-- Including CPU backend\n-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n-- Found OpenMP: TRUE (found version \"4.5\")\n-- x86 detected\n-- Adding CPU backend variant ggml-cpu: -march=native \n-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")\n-- Configuring done (2.0s)\n-- Generating done (0.3s)\n-- Build files have been written to: /kaggle/working/llama.cpp/build\n[  0%] Generating build details from Git\n[  3%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\n[  3%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\n[  7%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\n-- Found Git: /usr/bin/git (found version \"2.34.1\")\n[  7%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\n[  7%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\n[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\n[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\n[ 11%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\n[ 11%] Built target build_info\n[ 14%] Linking CXX static library libggml-base.a\n[ 14%] Built target ggml-base\n[ 18%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\n[ 18%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\n[ 18%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\n[ 22%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o\n[ 22%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o\n[ 25%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o\n[ 25%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\n[ 29%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\n[ 29%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\n[ 29%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\n[ 33%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\n[ 33%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\n[ 37%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\n[ 37%] Linking CXX static library libggml-cpu.a\n[ 37%] Built target ggml-cpu\n[ 40%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\n[ 40%] Linking CXX static library libggml.a\n[ 40%] Built target ggml\n[ 40%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\n[ 44%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o\n[ 44%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\n[ 48%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\n[ 51%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\n[ 51%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\n[ 55%] Building CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\n[ 55%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\n[ 55%] Building CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\n[ 59%] Building CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\n[ 59%] Building CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\n[ 62%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\n[ 62%] Building CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\n[ 66%] Building CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\n[ 66%] Building CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\n[ 66%] Building CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\n[ 70%] Building CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\n[ 70%] Building CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\n[ 74%] Building CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\n[ 74%] Building CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\n[ 77%] Building CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\n[ 77%] Linking CXX static library libllama.a\n[ 77%] Built target llama\n[ 77%] Building CXX object common/CMakeFiles/common.dir/chat.cpp.o\n[ 81%] Building CXX object common/CMakeFiles/common.dir/common.cpp.o\n[ 85%] Building CXX object common/CMakeFiles/common.dir/arg.cpp.o\n[ 85%] Building CXX object common/CMakeFiles/common.dir/console.cpp.o\n[ 88%] Building CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\n[ 88%] Building CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\n[ 88%] Building CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\n[ 92%] Building CXX object common/CMakeFiles/common.dir/log.cpp.o\n[ 92%] Building CXX object common/CMakeFiles/common.dir/sampling.cpp.o\n[ 96%] Building CXX object common/CMakeFiles/common.dir/speculative.cpp.o\n[ 96%] Linking CXX static library libcommon.a\n[ 96%] Built target common\n[100%] Building CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\n[100%] Linking CXX executable ../../bin/llama-quantize\n[100%] Built target llama-quantize\n[  0%] Built target build_info\n[ 14%] Built target ggml-base\n[ 37%] Built target ggml-cpu\n[ 40%] Built target ggml\n[ 77%] Built target llama\n[ 96%] Built target common\n[100%] Building CXX object tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\n[100%] Linking CXX executable ../../bin/llama-export-lora\n[100%] Built target llama-export-lora\n[  0%] Built target build_info\n[ 14%] Built target ggml-base\n[ 37%] Built target ggml-cpu\n[ 40%] Built target ggml\n[ 77%] Built target llama\n[ 96%] Built target common\n[ 96%] Building CXX object tools/main/CMakeFiles/llama-cli.dir/main.cpp.o\n[100%] Linking CXX executable ../../bin/llama-cli\n[100%] Built target llama-cli\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\nWe shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\nTo force `safe_serialization`, set it to `None` instead.\nUnsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\nmodel which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\nUnsloth: Will remove a cached repo with size 2.2G\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 19.93 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28/28 [00:00<00:00, 46.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving falcon281/RickLLama-3.2-3B/pytorch_model-00001-of-00002.bin...\nUnsloth: Saving falcon281/RickLLama-3.2-3B/pytorch_model-00002-of-00002.bin...\nDone.\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Converting llama model. Can use fast conversion = False.\n","output_type":"stream"},{"name":"stdout","text":"==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\nO^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n\\        /    [2] Converting GGUF 16bits to ['q8_0'] might take 10 minutes each.\n \"-____-\"     In total, you will have to wait at least 16 minutes.\n\nUnsloth: Installing llama.cpp. This might take 3 minutes...\nUnsloth: [1] Converting model at falcon281/RickLLama-3.2-3B into q8_0 GGUF format.\nThe output location will be /kaggle/working/falcon281/RickLLama-3.2-3B/unsloth.Q8_0.gguf\nThis might take 3 minutes...\nWriting: 100%|██████████| 3.41G/3.41G [01:17<00:00, 44.0Mbyte/s]\nUnsloth: Conversion completed! Output location: /kaggle/working/falcon281/RickLLama-3.2-3B/unsloth.Q8_0.gguf\nUnsloth: Saved Ollama Modelfile to falcon281/RickLLama-3.2-3B/Modelfile\nUnsloth: Uploading GGUF to Huggingface Hub...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"unsloth.Q8_0.gguf:   0%|          | 0.00/3.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cdb2e6186684537a0a830565c7b4aff"}},"metadata":{}},{"name":"stdout","text":"Saved GGUF to https://huggingface.co/falcon281/RickLLama-3.2-3B\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\nUnsloth: ##### The current model auto adds a BOS token.\nUnsloth: ##### We removed it in GGUF's chat template for you.\n","output_type":"stream"},{"name":"stdout","text":"Saved Ollama Modelfile to https://huggingface.co/falcon281/RickLLama-3.2-3B\n","output_type":"stream"}],"execution_count":49}]}